{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree\n",
    "- We'll be introduced to various ways to make sure any model we're asked to create or discuss is generalizable, evaluated correctly, and properly selected from among other possible models.\n",
    "- Here we'll tune min_samples_split, which is the minimum number of samples required to create an additional binary split, and max_depth, which is how deep we want to grow the tree. The deeper a tree, the more splits and therefore captures more information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv('data/Loan payments data.csv')\n",
    "# X\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=123)\n",
    "\n",
    "# Instantiate, Fit, Predict\n",
    "loans_clf = DecisionTreeClassifier() \n",
    "loans_clf.fit(X_train, y_train)\n",
    "y_pred = loans_clf.predict(X_test)\n",
    "\n",
    "# Evaluation metric\n",
    "print(\"Decision Tree Accuracy: {}\".format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the correct function to perform cross-validated grid search.\n",
    "- Instantiate a decision tree classifier and use it with the parameter grid to perform a cross-validated grid-search.\n",
    "- Fit and print model evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hyperparameter grid\n",
    "param_grid = {\"criterion\": [\"gini\"], \"min_samples_split\": [2, 10, 20], \n",
    "              \"max_depth\": [None, 2, 5, 10]}\n",
    "\n",
    "# Instantiate classifier and GridSearchCV, fit\n",
    "loans_clf = DecisionTreeClassifier()\n",
    "dtree_cv = GridSearchCV(loans_clf, param_grid, cv=5)\n",
    "fit = dtree_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Decision Tree Parameter: {}\".format(dtree_cv.best_params_))\n",
    "print(\"Tuned Decision Tree Accuracy: {}\".format(dtree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold cross-validation improved the accuracy of a decision tree model by more than 10 percent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A forest of decision trees\n",
    "- **Task** : practice using the bootstrapped Decision Tree, otherwise known as the Random Forest.We'll then compare its accuracy to a model where we've tuned hyperparameters with cross-validation. \n",
    "\n",
    "- This time, we'll tune an additional hyperparameter, **max_features**, which lets our **model decide how many features to use**. When it is not set specifically, then it defaults to auto. Something to keep in mind for an interview is that Decision Trees consider all features by default, whereas Random Forests usually consider the square root of the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=123)\n",
    "\n",
    "# Instantiate, Fit, Predict\n",
    "loans_rf = RandomForestClassifier() \n",
    "loans_rf.fit(X_train, y_train)\n",
    "y_pred = loans_rf.predict(X_test)\n",
    "\n",
    "# Evaluation metric\n",
    "print(\"Random Forest Accuracy: {}\".format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hyperparameter grid\n",
    "param_grid = {\"criterion\": [\"gini\"], \"min_samples_split\": [2, 10, 20], \n",
    "              \"max_depth\": [None, 2, 5, 10],\"max_features\": [10, 20, 30]}\n",
    "\n",
    "# Instantiate classifier and GridSearchCV, fit\n",
    "loans_rf = RandomForestClassifier()\n",
    "rf_cv = GridSearchCV(loans_rf, param_grid, cv=5)\n",
    "fit = rf_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Random Forest Parameter: {}\".format(rf_cv.best_params_))\n",
    "print(\"Tuned Random Forest Accuracy: {}\".format(rf_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Although k-fold cross-validation did not improve a random forest model as much as it did for the decision tree, it had a 7 percent improvement over the baseline!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
